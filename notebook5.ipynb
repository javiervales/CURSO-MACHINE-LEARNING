{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  <head>\n",
    "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n",
    "    <meta http-equiv=\"Content-Style-Type\" content=\"text/css\" />\n",
    "    <meta name=\"generator\" content=\"pandoc\" />\n",
    "    <title></title>\n",
    "    <style type=\"text/css\">code{white-space: pre;}</style>\n",
    "  </head>\n",
    "  \n",
    "\n",
    "# MACHINE LEARNING FOR RESEARCHERS\n",
    "\n",
    "# Notebook 5. Redes Neuronales Artificiales\n",
    "\n",
    "\n",
    "    \n",
    "Este notebook presenta una introducción a las redes neuronales artificiales. Se empleará la librería de alto nivel **Keras**, que empleará **Tensorflow** para crear los grafos asociados a las redes. Como ejemplos demostrativos se abordarán los ejemplos de base mostrados en el Notebook 1 (regresión y clasificación)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Redes Neuronales\n",
    "\n",
    "Una red neuronal artificial **(Artificial Neural Network - ANN)** es una\n",
    "  estructura que permite crear modelos de predicción **no lineales**. Se\n",
    "  emplean tanto en aprendizaje supervisado como no supervisado. En aprendizaje\n",
    "  supervisado permiten implementar sistemas regresores (incluidos multi-target),\n",
    "  y clasificadores probabilísticos (binarios o multiclase).\n",
    "  \n",
    "Al crear modelos no lineales permiten usar **bases con un número fijo de\n",
    "  características** pero que serán **adaptativas**, i.e., que se ajustarán\n",
    "  automáticamente a los datos de entrenamiento. Como penalización, resultan\n",
    "  **funciones de coste no convexas**, por lo que hay que desarrollar\n",
    "  algoritmos de entrenamiento específicos, como **back-propagation**.\n",
    "  \n",
    "  La red posee una **capa de entrada**, con $D$ entradas, un por cada variable de la instancia $\\pmb{x}$.  A continuación hay $L$ capas, cada una con $M(l)$ nodos.  Las $L-1$ primeras capas se llaman **capas ocultas**, tras ella está la **capa de salida**, con tantas salidas $K$ como dimensiones tenga el **target** a predecir.\n",
    "\n",
    "  Cada una de los nodos de las capas se denomina **neurona**, por analogía con las redes neuronales biológicas. La salida del nodo $i$ de la capa $l$ se denota $z^{(l)}_i$, o simplemente $x_i$ o $y_i$ para las capas de entrada y de salida, respectivamente.  Se asume además un nodo extra $x_0$=1, y $z^{(l)}_0$=1 para permitir un término de bias. \n",
    "  \n",
    "  Las redes se identifican según el número de $L$-capas. \n",
    "  \n",
    " De una capa a la siguiente, la salida del nodo $i$ se pondera por un peso\n",
    "  $w^{(l)}_{ji}$, siendo $l$ la capa y $j$ el nodo de la capa $l$.\n",
    "\n",
    "  La suma ponderada por los pesos de las entradas a un nodo se llama **activación**. Para\n",
    "  el nodo $j$ de la capa $l$ viene dado por:\n",
    "  \n",
    "  \\begin{equation*}\n",
    "  a^{(l)}_j = \\sum_{i=0}^{M(l)} w^{(l)}_{ji} z_i\n",
    "  \\end{equation*}\n",
    "\n",
    "  Esa entrada se transforma usando una **función de activación** $h(\\cdot)$ para generar la salida\n",
    "  hacia la siguiente capa:\n",
    "  \n",
    "  \\begin{equation*}\n",
    "  z^{(l)}_j = h(a^{l}_j) = h\\left(\\sum_{i=0}^{M(l)} w^{(l)}_{ji} z_i\\right)\n",
    "  \\end{equation*}\n",
    "\n",
    "  La función de activación dependerá de la capa (o nodo) y se escoge **no-lineal y diferenciable**.\n",
    " \n",
    "  \n",
    "  A continuación crearemos una red de 2-capas con $M$ neuronas en la capa oculpa para tratar el problema base de regresión planteado en el Notebook 1. **Al tratarse de un problema de regresión se escoge como activación en la última capa la función identidad**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problemas de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:23:35.233864Z",
     "start_time": "2020-03-09T19:23:34.424635Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bibliotecas necesarias\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Configuramos matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Semilla fija para reproducibilidad\n",
    "np.random.seed(1)\n",
    "\n",
    "# Generamos data set\n",
    "X = np.linspace(0,1,num=10) # Tipo lista\n",
    "X = np.array([X]).T # Lo pasamos a vector \"columna\" en numpy (tipo ndarray)\n",
    "t = np.sin(2*np.pi*X) + 0.1*np.random.randn(10, 1) \n",
    "xfull = np.linspace(0,1,num=100);\n",
    "xfull = np.array([xfull]).T \n",
    "treal = np.sin(2*np.pi*xfull);\n",
    "\n",
    "# Data set plotting\n",
    "plt.plot(X, t, \"b.\")\n",
    "plt.plot(xfull, treal, \"g-\")\n",
    "plt.xlabel(\"$x$\", fontsize=18)\n",
    "plt.ylabel(\"$t$\", rotation=0, fontsize=18)\n",
    "plt.axis([0, 1, -1.5, 1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:31:30.428978Z",
     "start_time": "2020-03-09T19:23:35.235533Z"
    }
   },
   "outputs": [],
   "source": [
    " # Entrenamos un autoencoder construido en keras\n",
    "import keras\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "\n",
    "M=3\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(M, activation=\"tanh\", input_shape=X.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X, t, epochs=100000, batch_size=2) # Calcula los pesos óptimos dado el training set X,t\n",
    "\n",
    "y = model.predict(xfull)  # Precide nuevos puntos\n",
    "\n",
    "plt.plot(xfull, y, \"r-\")\n",
    "plt.plot(xfull, treal, \"g-\")\n",
    "plt.plot(X, t, \"b.\")\n",
    "plt.axis([0, 1, -1.5, 1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe como el tiempo de entrenamiento es **mucho mayor** que con el regresor logístico. La ventaja es que en ningún momento debe crearse una matriz de diseño, **¡¡la red neuronal se ocupa de encontrar la mejor transformación al espacio de características!!**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T15:37:50.406986Z",
     "start_time": "2020-03-09T15:37:50.404980Z"
    }
   },
   "source": [
    "### Problemas de clasificación\n",
    "\n",
    "Vamos a aplicar ahora una ANN para la clasificación del data set Esfericos vs. Toroidales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:31:30.612652Z",
     "start_time": "2020-03-09T19:31:30.430739Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "r = np.random.rand(50, 1) #0...1\n",
    "a = 2*np.pi*np.random.rand(50,1) #0..2pi\n",
    "X_0 = np.c_[r*np.cos(a), r*np.sin(a)]\n",
    "\n",
    "r = 0.9 + np.random.rand(50, 1) #0.9...1.9\n",
    "a = 2*np.pi*np.random.rand(50,1) #0..2pi\n",
    "X_1 = np.c_[r*np.cos(a), r*np.sin(a)]\n",
    "\n",
    "X = np.r_[X_0, X_1]\n",
    "t = np.r_[np.zeros([50,1]),np.ones([50,1])]\n",
    "\n",
    "# Plot data set\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(X[t.reshape(X.shape[0],)==0, 0], X[t.reshape(X.shape[0],)==0, 1], \"bs\")\n",
    "plt.plot(X[t.reshape(X.shape[0],)==1, 0], X[t.reshape(X.shape[0],)==1, 1], \"g^\")\n",
    "\n",
    "plt.axis([-2, 2, -2, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:33:53.434263Z",
     "start_time": "2020-03-09T19:31:30.614398Z"
    }
   },
   "outputs": [],
   "source": [
    "# Entrenamos un autoencoder construido en keras\n",
    "import keras\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X)\n",
    "\n",
    "M=3\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(M, activation=\"relu\", input_shape=X.shape[1:]),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, t, epochs=20000) # Calcula los pesos óptimos dado el training set X,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:33:53.965041Z",
     "start_time": "2020-03-09T19:33:53.436601Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the decision boundary\n",
    "x0, x1 = np.meshgrid(np.linspace(-2, 2, 100).reshape(-1, 1), np.linspace(-2, 2, 100).reshape(-1, 1),)\n",
    "xfull = np.c_[x0.ravel(), x1.ravel()]\n",
    "yfull = model.predict_proba(xfull)  # Precide la probabilidad de nuevos puntos\n",
    "\n",
    "# Plot data set\n",
    "zz = yfull.reshape(x0.shape)\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "left_right = np.array([2.9, 7])\n",
    "\n",
    "contour = plt.contour(x0, x1, zz, levels=[0.1, 0.5, 0.9], cmap=plt.cm.brg)\n",
    "plt.clabel(contour, inline=1, fontsize=12)\n",
    "plt.plot(X[t.reshape(X.shape[0],)==0, 0], X[t.reshape(X.shape[0],)==0, 1], \"bs\")\n",
    "plt.plot(X[t.reshape(X.shape[0],)==1, 0], X[t.reshape(X.shape[0],)==1, 1], \"g^\")\n",
    "plt.axis([-2, 2, -2, 2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en el ejemplo de regresión **el tiempo de entrenamiento se incrementa notablemente**. Como contrapartida **la búsqueda de características es automática**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:33:54.003107Z",
     "start_time": "2020-03-09T19:33:53.967107Z"
    }
   },
   "outputs": [],
   "source": [
    "# Guardar modelo\n",
    "model_json = model.to_json()\n",
    "with open(\"SvsT.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"SvsT.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:33:54.670510Z",
     "start_time": "2020-03-09T19:33:54.004546Z"
    }
   },
   "outputs": [],
   "source": [
    "json_file = open('SvsT.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"SvsT.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_train, t, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo completo: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizaremos ahora un ejemplo realista: la clasificación MNIST, al que le añadiremos la siguientes características:\n",
    "\n",
    "- Early stopping y guardado y recuperación automáticos del modelo\n",
    "- Evaluación final versus conjunto de test\n",
    "- Clasificador multiclase basado en **softmax**\n",
    "- Normalización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:34:19.081646Z",
     "start_time": "2020-03-09T19:33:54.673686Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "# print(mnist.DESCR) # Uncomment to show description\n",
    "X, t = mnist[\"data\"], mnist[\"target\"] # N = 70000, D = 784 \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X, t = shuffle(X, t, random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, t_train, t_test = X[:60000], X[60000:], t[:60000], t[60000:]\n",
    "X_train, X_valid, t_train, t_valid = X_train[:50000], X_train[50000:], t_train[:50000], t_train[50000:] \n",
    "\n",
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.plasma, **options)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:47:05.110885Z",
     "start_time": "2020-03-09T19:46:29.866146Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(300, activation=\"relu\", input_shape=X.shape[1:]),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "try: \n",
    "    model = keras.models.load_model(\"modelo.h5\") # cargar modelo\n",
    "except:\n",
    "    pass\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"modelo.h5\", save_best_only=True)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, t_train, epochs=50, batch_size=1000, validation_data=(X_valid, t_valid), callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-09T19:47:29.031665Z",
     "start_time": "2020-03-09T19:47:12.342163Z"
    }
   },
   "outputs": [],
   "source": [
    "print(history.params)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "#print(clf.best_params_)\n",
    "\n",
    "print(f'The score (accurary) in the training set is {model.evaluate(X_train,t_train)[1]*100:.02f}%')\n",
    "print(f'The score (accuracy) in the test set is {model.evaluate(X_test,t_test)[1]*100:.02f}%\\n')\n",
    "\n",
    "plot_digits(scaler.inverse_transform(X_test[:10]), images_per_row=10)\n",
    "print('Labels predicted for the 10 first pictures in the test set')\n",
    "print(model.predict_classes(X_test[:10]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1163px",
    "left": "1185.6px",
    "top": "111.133px",
    "width": "344.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
